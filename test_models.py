"""
æ¸¬è©¦æ‰€æœ‰æ¨¡å‹æ˜¯å¦å¯ç”¨
"""

import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPEN_ROUTER_KEY"),
)

# æ‰€æœ‰å¾…æ¸¬è©¦çš„æ¨¡å‹
MODELS = [
    # lawful
    "openai/gpt-4o-mini",
    "openai/gpt-4o",
    "anthropic/claude-3.5-sonnet",
    "anthropic/claude-3-haiku",
    
    # chaotic
    "meta-llama/llama-3.1-8b-instruct",
    "meta-llama/llama-3.1-70b-instruct",
    "meta-llama/llama-3.1-405b-instruct",
    "mistralai/mistral-7b-instruct",
    "mistralai/mistral-large",
    "mistralai/mixtral-8x7b-instruct",
    "google/gemma-2-9b-it",
    "google/gemma-2-27b-it",
    "deepseek/deepseek-chat",
    "qwen/qwen-2.5-72b-instruct",
    "mistralai/mistral-nemo",
    "x-ai/grok-3-mini",
    
    # uncensored
    "nousresearch/hermes-3-llama-3.1-405b:free",
    
    # experimental
    "meta-llama/llama-3-8b-instruct",
    "meta-llama/llama-3.2-3b-instruct",
    "microsoft/wizardlm-2-8x22b",
]

print("ğŸ” é–‹å§‹æ¸¬è©¦æ¨¡å‹...\n")
print("=" * 70)

working_models = []
failed_models = []

for i, model in enumerate(MODELS, 1):
    print(f"\n[{i}/{len(MODELS)}] æ¸¬è©¦: {model}")
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": "Hi"}
            ],
            max_tokens=5,
            temperature=0.3,
        )
        
        content = response.choices[0].message.content
        print(f"  âœ… æˆåŠŸ: {content[:30]}...")
        working_models.append(model)
        
    except Exception as e:
        error_msg = str(e)
        if "404" in error_msg:
            print(f"  âŒ å¤±æ•— (404): æ¨¡å‹ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨")
        elif "429" in error_msg:
            print(f"  â³ å¤±æ•— (429): Rate limit (å¯èƒ½è‡¨æ™‚æ€§)")
        else:
            print(f"  âŒ å¤±æ•—: {error_msg[:80]}")
        
        failed_models.append((model, error_msg))

print("\n" + "=" * 70)
print("\nğŸ“Š æ¸¬è©¦çµæœ:")
print(f"  âœ… å¯ç”¨æ¨¡å‹: {len(working_models)} å€‹")
print(f"  âŒ å¤±æ•—æ¨¡å‹: {len(failed_models)} å€‹")

if working_models:
    print("\nâœ… å¯ç”¨æ¨¡å‹æ¸…å–®:")
    for model in working_models:
        print(f"  - {model}")

if failed_models:
    print("\nâŒ å¤±æ•—æ¨¡å‹æ¸…å–®:")
    for model, error in failed_models:
        if "404" in error:
            print(f"  - {model} (404 - ä¸å­˜åœ¨)")
        elif "429" in error:
            print(f"  - {model} (429 - Rate limit)")
        else:
            print(f"  - {model} (å…¶ä»–éŒ¯èª¤)")

print("\n" + "=" * 70)
print(f"\næœ€çµ‚å¯ç”¨æ¨¡å‹æ•¸é‡: {len(working_models)}/20")

if len(working_models) < 20:
    print(f"\nâš ï¸ éœ€è¦æ›¿æ› {20 - len(working_models)} å€‹æ¨¡å‹")
